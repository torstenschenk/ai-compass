{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9188351f",
   "metadata": {},
   "source": [
    "# AI-Compass: A/B Testing Validation Framework\n",
    "### Strategic Rationale\n",
    "To prove the value of AI/ML, we shouldn't just replace the existing logic. High-stakes consulting tools require **A/B Testing** to measure user engagement, trust, and conversion.\n",
    "\n",
    "**This notebook simulates the two \"Insight Modes\":**\n",
    "1.  **Group A: Deterministic (Rules)**: The current \"Safe\" approach using linear averages and hard-coded mappings.\n",
    "2.  **Group B: Probabilistic (AI/ML)**: The \"Intelligent\" approach using clustering, percentiles, and peer-benchmarking.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7efaed19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.stats import percentileofscore\n",
    "from dotenv import load_dotenv\n",
    "import psycopg2\n",
    "\n",
    "# Visualization\n",
    "sns.set_theme(style=\"white\")\n",
    "plt.rcParams['figure.figsize'] = [10, 6]\n",
    "\n",
    "# DB Connection\n",
    "load_dotenv()\n",
    "db_url = os.getenv(\"DATABASE_URL\")\n",
    "conn = psycopg2.connect(db_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f201c",
   "metadata": {},
   "source": [
    "## 1. The Data Engine\n",
    "The engine fetches the 1-5 maturity scores (excluding Psychology) that both groups will use as input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fec1a11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/gzyj3_ks2_s0smrmyspjtc2h0000gn/T/ipykernel_3573/955720025.py:16: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data engine ready. Processing 500 companies.\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    r.company_id,\n",
    "    c.industry,\n",
    "    d.dimension_name,\n",
    "    a.answer_weight\n",
    "FROM response_items ri\n",
    "JOIN responses r ON r.response_id = ri.response_id\n",
    "JOIN companies c ON c.company_id = r.company_id\n",
    "JOIN questions q ON q.question_id = ri.question_id\n",
    "JOIN dimensions d ON d.dimension_id = q.dimension_id\n",
    "JOIN answers a ON a.answer_id = ri.answers[1]\n",
    "WHERE d.dimension_name != 'General Psychology'\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Prepare Features\n",
    "df_features = df.groupby(['company_id', 'industry', 'dimension_name'])['answer_weight'].mean().reset_index()\n",
    "df_features = df_features.pivot(index=['company_id', 'industry'], columns='dimension_name', values='answer_weight').fillna(0)\n",
    "# Scale to 1-5\n",
    "df_features = 1 + 4 * (df_features - df_features.min()) / (df_features.max() - df_features.min())\n",
    "\n",
    "# Calculate total score for rule-based\n",
    "df_features['total_score'] = df_features.mean(axis=1)\n",
    "\n",
    "# Preparation for ML (Clustering)\n",
    "X = df_features.drop(columns=['total_score'])\n",
    "kmeans = KMeans(n_clusters=5, random_state=42, n_init=10).fit(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "print(f\"Data engine ready. Processing {len(df_features)} companies.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741aaf4",
   "metadata": {},
   "source": [
    "## 2. Group A Logic (Deterministic Rules)\n",
    "This group sees the world through static rules and global averages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2883934",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s4/gzyj3_ks2_s0smrmyspjtc2h0000gn/T/ipykernel_3573/3752667600.py:2: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df_rules = pd.read_sql(\"SELECT * FROM cluster_profiles\", conn)\n"
     ]
    }
   ],
   "source": [
    "# Fetch Rule Definitions\n",
    "df_rules = pd.read_sql(\"SELECT * FROM cluster_profiles\", conn)\n",
    "df_rules['score_min'] = df_rules['score_min'].astype(float)\n",
    "df_rules['score_max'] = df_rules['score_max'].astype(float)\n",
    "\n",
    "global_avg = df_features['total_score'].mean()\n",
    "\n",
    "def get_group_a_insights(company_id):\n",
    "    row = df_features.loc[company_id]\n",
    "    score = row['total_score']\n",
    "    \n",
    "    # 1. Profile Assignment (Deterministic)\n",
    "    profile = \"Unknown\"\n",
    "    for _, r in df_rules.iterrows():\n",
    "        if r['score_min'] <= score <= r['score_max']:\n",
    "            profile = f\"{r['cluster_name']} (Score {score:.1f})\"\n",
    "            break\n",
    "            \n",
    "    # 2. Benchmarking (Simple Average)\n",
    "    benchmarking = f\"You are {'above' if score >= global_avg else 'below'} average ({score:.1f} vs {global_avg:.1f})\"\n",
    "    \n",
    "    # 3. Recommendation (Static Mapping)\n",
    "    # Finding the lowest dimension\n",
    "    lowest_dim = row.drop('total_score').idxmin()\n",
    "    recommendation = f\"Static Rule: Your {lowest_dim} is lowest. Focus on improving this area first.\"\n",
    "    \n",
    "    return {\n",
    "        'Profile': profile,\n",
    "        'Benchmarking': benchmarking,\n",
    "        'Recommendation': recommendation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fc64ea",
   "metadata": {},
   "source": [
    "## 3. Group B Logic (Probabilistic AI/ML)\n",
    "This group sees similarities, percentiles, and peer-driven success paths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62a8d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_group_b_insights(company_id):\n",
    "    row = df_features.loc[company_id]\n",
    "    data = row.drop('total_score').values.reshape(1, -1)\n",
    "    score = row['total_score']\n",
    "    industry = company_id[1]\n",
    "    \n",
    "    # 1. Profile Assignment (Cluster Match %)\n",
    "    distances = np.linalg.norm(centroids - data, axis=1)\n",
    "    # Convert distances to probabilities (Match %)\n",
    "    probs = 1 / (distances + 1e-5)\n",
    "    probs = probs / probs.sum()\n",
    "    best_cluster = np.argmax(probs)\n",
    "    match_pct = probs[best_cluster] * 100\n",
    "    profile = f\"Nearest to Cluster {best_cluster} ({match_pct:.0f}% structural match)\"\n",
    "    \n",
    "    # 2. Benchmarking (Percentile in Industry/Peer Group)\n",
    "    industry_scores = df_features.xs(industry, level='industry')['total_score']\n",
    "    percentile = percentileofscore(industry_scores, score)\n",
    "    benchmarking = f\"You are in the top {100-percentile:.0f}% of your '{industry}' peer group.\"\n",
    "    \n",
    "    # 3. Recommendation (Lookalike Pathway)\n",
    "    # Simplified Peer-based: Recommend the dimension where the top 10% of industry excel most vs user\n",
    "    top_peers = industry_scores[industry_scores > score].sort_values(ascending=False).head(10)\n",
    "    if not top_peers.empty:\n",
    "        peer_idx = top_peers.index\n",
    "        peer_data = df_features.loc[(slice(None), industry), :].loc[peer_idx].drop(columns=['total_score']).mean()\n",
    "        gap = peer_data - row.drop('total_score')\n",
    "        recommendation = f\"Peer Insight: Companies similar to you that reached the next level focused on '{gap.idxmax()}'.\"\n",
    "    else:\n",
    "        recommendation = \"Peer Insight: You are leading your industry. Explore niche AI innovations.\"\n",
    "        \n",
    "    return {\n",
    "        'Profile': profile,\n",
    "        'Benchmarking': benchmarking,\n",
    "        'Recommendation': recommendation\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e5fc3",
   "metadata": {},
   "source": [
    "## 4. The Result: A/B Testing Dashboard\n",
    "Here is what the **same user** would see in Group A vs. Group B. Note the difference in tone and precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b19b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPORT FOR COMPANY ID: 33 (Industry: Manufacturing)\n",
      "================================================================================\n",
      "FEATURE              | GROUP A (DETERMINISTIC)        | GROUP B (PROBABILISTIC)       \n",
      "--------------------------------------------------------------------------------\n",
      "Profile              | The Experimental Explorer (Score 2.4) | Nearest to Cluster 2 (44% structural match)\n",
      "Benchmarking         | You are below average (2.4 vs 2.6) | You are in the top 55% of your 'Manufacturing' peer group.\n",
      "Recommendation       | Static Rule: Your People & Culture is lowest. Focus on improving this area first. | Peer Insight: Companies similar to you that reached the next level focused on 'People & Culture'.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "def render_ab_comparison(company_id):\n",
    "    a = get_group_a_insights(company_id)\n",
    "    b = get_group_b_insights(company_id)\n",
    "    \n",
    "    print(f\"REPORT FOR COMPANY ID: {company_id[0]} (Industry: {company_id[1]})\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"{'FEATURE':<20} | {'GROUP A (DETERMINISTIC)':<30} | {'GROUP B (PROBABILISTIC)':<30}\")\n",
    "    print(\"-\"*80)\n",
    "    print(f\"{'Profile':<20} | {a['Profile']:<30} | {b['Profile']:<30}\")\n",
    "    print(f\"{'Benchmarking':<20} | {a['Benchmarking']:<30} | {b['Benchmarking']:<30}\")\n",
    "    print(f\"{'Recommendation':<20} | {a['Recommendation']:<30} | {b['Recommendation']:<30}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "# Pick a sample company\n",
    "sample_cid = df_features.index[10]\n",
    "render_ab_comparison(sample_cid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af172958",
   "metadata": {},
   "source": [
    "## 5. Summary & Next Steps\n",
    "**Key Observations:**\n",
    "- **Group A** is easy to explain but feels like a \"form letter\".\n",
    "- **Group B** provides high-precision insights that feel personalized and data-backed.\n",
    "\n",
    "**Validation Strategy:**\n",
    "1.  **Metric**: \"Click-through rate\" on the Recommendation.\n",
    "2.  **Metric**: User Rating (1-5 stars) on \"How accurate does this feel?\".\n",
    "3.  **A/B Test Execution**: Randomly hash the `user_id` to assign A or B in the backend and track these metrics in your database.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
